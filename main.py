from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import urllib.request
import json
import os
import ssl
import random

app = FastAPI(title="Casablanca Traffic Predictor üöó", version="1.0")

app.mount("/static", StaticFiles(directory="static"), name="static")

# ==========================================
# ‚öôÔ∏è Configuration de la connexion Azure
# Remplacez les cl√©s ci-dessous par les v√¥tres
# ==========================================
url = "https://traffic-ml-workspace-v2-twvwz.norwayeast.inference.ml.azure.com/score"  # Point de terminaison (Endpoint)
api_key = "G4KvLxZfhCBTIKPjpB9k2XxinGY0UZ9vTX1Mv6HjdfLeFTXtEZpgJQQJ99CBAAAAAAAAAAAAINFRAZML4BES"   # Cl√© d'API (Primary Key)
# ==========================================

def allowSelfSignedHttps(allowed):
    # Cette fonction permet de contourner les erreurs SSL si n√©cessaire (utile pour le debug local)
    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):
        ssl._create_default_https_context = ssl._create_unverified_context

allowSelfSignedHttps(True)

@app.get("/")
def home():
    return FileResponse('static/index.html')

@app.get("/health")
def health():
    return {"message": "API Traffic Casa is Running! Go to /docs to test."}

@app.post("/predict_traffic")
def predict(zone: str, hour: int, day: str):
    # === üõ†Ô∏è Gestion de la casse (Case Sensitivity) ===
    # On s'assure que "maarif" devient "Maarif" pour correspondre au mod√®le
    zone = zone.title()
    day = day.title()
    
    # === üåê Plan A : Tentative de connexion √† Azure ===
    azure_result = None
    try:
        data = {"data": [[zone, hour, day]]}
        body = str.encode(json.dumps(data))
        headers = {
            'Content-Type': 'application/json',
            'Authorization': ('Bearer ' + api_key),
            'AzureML-Model-Deployment': 'traffic-model-1'
        }
        
        req = urllib.request.Request(url, body, headers)
        response = urllib.request.urlopen(req)
        result_str = response.read().decode('utf-8')
        
        # V√©rification de la r√©ponse : on s'attend √† une liste contenant un nombre (ex: [0.85])
        parsed_result = json.loads(result_str)
        if isinstance(parsed_result, list) and isinstance(parsed_result[0], (int, float)):
            azure_result = float(parsed_result[0])
        else:
            print(f"‚ö†Ô∏è Alerte Azure : R√©ponse inattendue : {result_str}")

    except Exception as e:
        print(f"‚ö†Ô∏è √âchec de connexion Azure : {e}")
        # En cas d'erreur r√©seau, on continue l'ex√©cution pour basculer vers le mode secours
    
    # === üõ°Ô∏è Plan B : Mode Secours (Fallback Local) ===
    # Si Azure ne r√©pond pas, on utilise une simulation locale pour √©viter de bloquer la d√©mo
    if azure_result is not None:
        congestion_level = azure_result
        source = "Azure AI ‚òÅÔ∏è"
    else:
        # Simulation simple : Pics de trafic entre 8h-9h et 17h-19h
        is_peak = (8 <= hour <= 9) or (17 <= hour <= 19)
        base_traffic = 0.8 if is_peak else 0.3
        
        # Ajout d'une l√©g√®re variation al√©atoire pour rendre la simulation plus r√©aliste
        congestion_level = base_traffic + random.uniform(-0.1, 0.1)
        # On borne le r√©sultat entre 0 et 1
        congestion_level = max(0.0, min(1.0, congestion_level))
        source = "Mod√®le Local (Secours) üíª"

    # === üé® Formatage du r√©sultat pour l'interface ===
    status = "üü¢ Fluide"
    if congestion_level > 0.7:
        status = "üî¥ Embouteillage (√âviter)"
    elif congestion_level > 0.4:
        status = "üü† Trafic Dense"

    print(f"‚úÖ Pr√©diction : {congestion_level:.2f} | Source : {source}")

    return {
        "Zone": zone,
        "Hour": f"{hour}:00",
        "Day": day,
        "Predicted_Congestion": round(congestion_level, 2),
        "Status": status
    }