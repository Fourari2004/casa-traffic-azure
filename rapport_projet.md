# üöó Rapport Technique : Smart Traffic Prediction (Casablanca)

## üìã Pr√©sentation du Projet
Ce projet vise √† pr√©dire le niveau de congestion routi√®re √† Casablanca en utilisant l'Intelligence Artificielle sur le Cloud Azure. L'objectif est de fournir une estimation en temps r√©el (Fluide, Mod√©r√©, Bloqu√©) bas√©e sur la zone, l'heure et le jour de la semaine.

---

## üèóÔ∏è Architecture Cloud (Azure)

La solution repose sur une architecture **PaaS (Platform as a Service)** optimis√©e pour le co√ªt et la performance :

1.  **Azure SQL Database :** Stockage structur√© des donn√©es historiques (Scalabilit√© & S√©curit√©).
2.  **Azure Blob Storage :** Stockage des fichiers bruts (`csv`) pour l'entra√Ænement du mod√®le.
3.  **Azure Machine Learning :** Cr√©ation, entra√Ænement et d√©ploiement du mod√®le d'IA.
4.  **Azure Container Instance (ACI) :** H√©bergement de l'API du mod√®le (Endpoint).
5.  **Client Application (FastAPI) :** Interface utilisateur locale communiquant avec le Cloud.

---

## üõ†Ô∏è √âtapes de R√©alisation (D√©tails Techniques)

### 1Ô∏è‚É£ Base de Donn√©es (Azure SQL)
* **Service :** SQL Database (Tier Basic).
* **Configuration :** Serveur s√©curis√© avec authentification SQL.
* **Sch√©ma :** Cr√©ation de la table `traffic_data` pour stocker l'historique (Zone, Heure, Jour, Niveau de traffic).
* **R√¥le :** Assure la gouvernance des donn√©es et permet une √©volutivit√© future.

### 2Ô∏è‚É£ Stockage des Donn√©es (Blob Storage)
* **Service :** Storage Account (LRS - Locally Redundant Storage pour r√©duire les co√ªts).
* **Container :** `datasets`.
* **Fichier :** Upload du fichier `traffic_data.csv` contenant les donn√©es d'entra√Ænement.

### 3Ô∏è‚É£ Intelligence Artificielle (Azure Machine Learning)
Nous avons utilis√© l'approche **"No-Code / Low-Code"** avec le Designer Azure ML :

1.  **Ingestion :** Importation du dataset depuis le Blob Storage.
2.  **Split Data :** Division des donn√©es (70% pour l'entra√Ænement, 30% pour le test).
3.  **Algorithme :** Utilisation de la **R√©gression Lin√©aire** (Linear Regression) car nous pr√©disons une valeur continue (0 √† 1).
4.  **Entra√Ænement :** Le module "Train Model" apprend les corr√©lations entre (Heure/Jour/Zone) et le Traffic.
5.  **√âvaluation :** Le module "Score Model" compare les pr√©dictions avec la r√©alit√©.

### 4Ô∏è‚É£ D√©ploiement (Inference Pipeline)
Une fois le mod√®le entra√Æn√©, nous l'avons d√©ploy√© pour qu'il soit accessible via internet :
* **M√©thode :** Real-time Inference Pipeline.
* **Compute :** Azure Container Instance (ACI) - Solution l√©g√®re et rapide.
* **S√©curit√© :** Authentification par Cl√© API (Key-based).

---

## üíª D√©veloppement de l'Application (FastAPI)

Pour la d√©monstration, nous avons d√©velopp√© une application Python locale (`main.py`) utilisant **FastAPI**.

### Fonctionnalit√©s Cl√©s :
1.  **Interface Web :** HTML/CSS/JS moderne pour saisir la Zone, l'Heure et le Jour.
2.  **API Gateway :** Le script Python re√ßoit la demande du navigateur et la transmet √† Azure.
3.  **R√©silience (Robust Fallback) :**
    * L'application tente d'abord de contacter l'IA sur Azure.
    * *S√©curit√© :* Si la connexion Azure √©choue (timeout, erreur serveur), l'application bascule automatiquement sur une **logique locale de secours**.
    * Cela garantit que la d√©monstration **ne plante jamais** devant le public (Effet D√©mo garanti ‚úÖ).

### Extrait de la logique (Python) :
```python
# Tentative de connexion Azure
try:
    response = urllib.request.urlopen(req)
    congestion_level = float(json.loads(response.read())[0])
except:
    # Mode Secours (Fallback) si Azure ne r√©pond pas
    congestion_level = simulation_locale(hour)
```

---

## ‚ö†Ô∏è D√©fis Techniques et Solutions

Durant la r√©alisation, nous avons surmont√© plusieurs d√©fis techniques :

1.  **Erreur de Stockage Azure ML :** Le Workspace initial a perdu son lien avec le compte de stockage.
    *   *Solution :* Recreation propre du Workspace (`traffic-ml-workspace-v2`) pour garantir un environnement stable.

2.  **D√©ploiement du Mod√®le :** L'option de d√©ploiement automatique n'√©tait pas visible dans l'interface Designer.
    *   *Solution :* Passage √† un d√©ploiement manuel via l'enregistrement du mod√®le ("Register Model") puis cr√©ation de l'Endpoint en temps r√©el.

3.  **Sensibilit√© √† la Casse (Case Sensitivity) :** Le mod√®le rejetait "maarif" car il avait appris "Maarif".
    *   *Solution :* Normalisation automatique des entr√©es dans le code Python (`.title()`).

4.  **Stabilit√© de la D√©mo :** Risque de latence ou d'erreur 500 lors de l'appel API Azure.
    *   *Solution :* Impl√©mentation du "Plan de Secours" (Fallback) qui assure une r√©ponse instantan√©e m√™me en cas de panne Cloud.

---

## üí∞ Estimation des Co√ªts (Cost Optimization)

La solution a √©t√© con√ßue pour rester sous la barre des **20$ / mois** :

* **Azure SQL (Basic) :** ~5$ / mois.
* **Blob Storage (LRS) :** < 1$ / mois (quelques Mo).
* **Azure ML Compute :** Configuration avec **Auto-shutdown (15 min)** pour ne payer que l'utilisation r√©elle.
* **Container Instance :** Facturation √† la seconde (utilis√© uniquement lors des requ√™tes).

---

## üöÄ Comment lancer le projet

1. Ouvrir le terminal dans le dossier du projet.
2. Lancer le serveur (ou utiliser `run_app.bat`) :
```bash
python -m uvicorn main:app --reload
```

3. Ouvrir le navigateur sur : `http://127.0.0.1:8000`

---

**¬© 2026 - Projet Cloud Computing - Smart Traffic**
